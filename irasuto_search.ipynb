{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "irasuto_search.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Jj6CdHkLiElp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# あなたの文章に合った「いらすとや」画像をレコメンド♪（アルゴリズム実装編）\n",
        "\n",
        "解説記事: https://qiita.com/sonoisa/items/775ac4c7871ced6ed4c3"
      ]
    },
    {
      "metadata": {
        "id": "HywTtx2I9Jli",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab\n",
        "!apt-get -q -y install swig \n",
        "!pip install mecab-python3 pymagnitude"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ywcHUY-e9NV-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget \"https://www.floydhub.com/api/v1/resources/SnBYkUGB9PdsbQMWbBb9jn?content=true&download=true&rename=sonobe-datasets-fasttext_model-4\" -O sonobe-datasets-fasttext_model-4.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dg13sTf8-k3L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar xvf sonobe-datasets-fasttext_model-4.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ecs6gg32_nR7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget \"https://www.floydhub.com/api/v1/resources/n52RTWdCosGvud4gitpE5b/irasuto_items_part.json?content=true&rename=irasuto_items_partjson\" -O irasuto_items_part.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U4vFZ8Pl_s87",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pymagnitude import *\n",
        "fasttext_model = Magnitude(\"jawiki.ipadic.fasttext.ws5-neg5-epoch5.magnitude\", normalized=False, ngram_oov=True, case_insensitive=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "coMTs4EJgJQX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "similarities = fasttext_model.most_similar(positive=['王子', '女'], negative=['男'])\n",
        "similarities"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Offh5t0egMMf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def cos_sim(v1, v2):\n",
        "    v1 = v1 / np.linalg.norm(v1, axis=0, ord=2)\n",
        "    v2 = v2 / np.linalg.norm(v2, axis=0, ord=2)\n",
        "    return np.sum(v1 * v2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LNP2Lku-gb1J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/neologd/mecab-ipadic-neologd/wiki/Regexp.ja から引用・一部改変\n",
        "from __future__ import unicode_literals\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def unicode_normalize(cls, s):\n",
        "    pt = re.compile('([{}]+)'.format(cls))\n",
        "\n",
        "    def norm(c):\n",
        "        return unicodedata.normalize('NFKC', c) if pt.match(c) else c\n",
        "\n",
        "    s = ''.join(norm(x) for x in re.split(pt, s))\n",
        "    s = re.sub('－', '-', s)\n",
        "    return s\n",
        "\n",
        "def remove_extra_spaces(s):\n",
        "    s = re.sub('[ 　]+', ' ', s)\n",
        "    blocks = ''.join(('\\u4E00-\\u9FFF',  # CJK UNIFIED IDEOGRAPHS\n",
        "                      '\\u3040-\\u309F',  # HIRAGANA\n",
        "                      '\\u30A0-\\u30FF',  # KATAKANA\n",
        "                      '\\u3000-\\u303F',  # CJK SYMBOLS AND PUNCTUATION\n",
        "                      '\\uFF00-\\uFFEF'   # HALFWIDTH AND FULLWIDTH FORMS\n",
        "                      ))\n",
        "    basic_latin = '\\u0000-\\u007F'\n",
        "\n",
        "    def remove_space_between(cls1, cls2, s):\n",
        "        p = re.compile('([{}]) ([{}])'.format(cls1, cls2))\n",
        "        while p.search(s):\n",
        "            s = p.sub(r'\\1\\2', s)\n",
        "        return s\n",
        "\n",
        "    s = remove_space_between(blocks, blocks, s)\n",
        "    s = remove_space_between(blocks, basic_latin, s)\n",
        "    s = remove_space_between(basic_latin, blocks, s)\n",
        "    return s\n",
        "\n",
        "def normalize_neologd(s):\n",
        "    s = s.strip()\n",
        "    s = unicode_normalize('０-９Ａ-Ｚａ-ｚ｡-ﾟ', s)\n",
        "\n",
        "    def maketrans(f, t):\n",
        "        return {ord(x): ord(y) for x, y in zip(f, t)}\n",
        "\n",
        "    s = re.sub('[˗֊‐‑‒–⁃⁻₋−]+', '-', s)  # normalize hyphens\n",
        "    s = re.sub('[﹣－ｰ—―─━ー]+', 'ー', s)  # normalize choonpus\n",
        "    s = re.sub('[~∼∾〜〰～]+', '〜', s)  # normalize tildes (modified by Isao Sonobe)\n",
        "    s = s.translate(\n",
        "        maketrans('!\"#$%&\\'()*+,-./:;<=>?@[¥]^_`{|}~｡､･｢｣',\n",
        "              '！”＃＄％＆’（）＊＋，－．／：；＜＝＞？＠［￥］＾＿｀｛｜｝〜。、・「」'))\n",
        "\n",
        "    s = remove_extra_spaces(s)\n",
        "    s = unicode_normalize('！”＃＄％＆’（）＊＋，－．／：；＜＞？＠［￥］＾＿｀｛｜｝〜', s)  # keep ＝,・,「,」\n",
        "    s = re.sub('[’]', '\\'', s)\n",
        "    s = re.sub('[”]', '\"', s)\n",
        "    s = s.upper()\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uUKopvBPgepg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize_text(text):\n",
        "    return normalize_neologd(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qNTEhOoHggjX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import MeCab\n",
        "mecab = MeCab.Tagger() # MeCab.Tagger(\"-d /usr/local/lib/mecab/dic/ipadic\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PfhTrgB1g9NS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Morph(object):\n",
        "    def __init__(self, surface, pos, base):\n",
        "        self.surface = surface\n",
        "        self.pos = pos\n",
        "        self.base = base\n",
        "    def __repr__(self):\n",
        "        return str({\n",
        "            \"surface\": self.surface,\n",
        "            \"pos\": self.pos,\n",
        "            \"base\": self.base\n",
        "        })\n",
        "\n",
        "def tokenize(sentence):\n",
        "    sentence = normalize_text(sentence)\n",
        "    mecab.parse(\"\")\n",
        "    lines = mecab.parse(sentence).split(\"\\n\")\n",
        "    tokens = []\n",
        "    for line in lines:\n",
        "        elems = line.split(\"\\t\")\n",
        "        if len(elems) < 2:\n",
        "            continue\n",
        "        surface = elems[0]\n",
        "        if len(surface):\n",
        "            feature = elems[1].split(\",\")\n",
        "            base = surface if len(feature) < 7 or feature[6] == \"*\" else feature[6]\n",
        "            pos = \",\".join(feature[0:4])\n",
        "            tokens.append(Morph(surface=surface, pos=pos, base=base))\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qhAgsAudhZZ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenize(\"MeCabを用いて正規化済み文字列を形態素解析します！！\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vxx11g-Lhbhc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('irasuto_items_part.json', 'r') as items_file:\n",
        "    items = json.load(items_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jpGatGxohecN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stop_pos = {\n",
        "    \"助詞,格助詞,一般,*\",\n",
        "    \"助詞,格助詞,引用,*\",\n",
        "    \"助詞,格助詞,連語,*\",\n",
        "    \"助詞,係助詞,*,*\",\n",
        "    \"助詞,終助詞,*,*\",\n",
        "    \"助詞,接続助詞,*,*\",\n",
        "    \"助詞,特殊,*,*\",\n",
        "    \"助詞,副詞化,*,*\",\n",
        "    \"助詞,副助詞,*,*\",\n",
        "    \"助詞,副助詞／並立助詞／終助詞,*,*\",\n",
        "    \"助詞,並立助詞,*,*\",\n",
        "    \"助詞,連体化,*,*\",\n",
        "    \"助動詞,*,*,*\",\n",
        "    \"記号,句点,*,*\",\n",
        "    \"記号,読点,*,*\",\n",
        "    \"記号,空白,*,*\",\n",
        "    \"記号,一般,*,*\",\n",
        "    \"記号,アルファベット,*,*\",\n",
        "    \"記号,一般,*,*\",\n",
        "    \"記号,括弧開,*,*\",\n",
        "    \"記号,括弧閉,*,*\",\n",
        "    \"動詞,接尾,*,*\",\n",
        "    \"動詞,非自立,*,*\",\n",
        "    \"名詞,非自立,一般,*\",\n",
        "    \"名詞,非自立,形容動詞語幹,*\",\n",
        "    \"名詞,非自立,助動詞語幹,*\",\n",
        "    \"名詞,非自立,副詞可能,*\",\n",
        "    \"名詞,接尾,助動詞語幹,*\",\n",
        "    \"名詞,接尾,人名,*\",\n",
        "    \"接頭詞,名詞接続,*,*\"\n",
        "}\n",
        "\n",
        "vocab = {}\n",
        "for item in items:\n",
        "    desc = item[\"desc\"]\n",
        "    title = item[\"title\"]\n",
        "    tokens = tokenize(desc)\n",
        "    for token in tokens:\n",
        "        key = token.base\n",
        "        pos = token.pos\n",
        "        is_stop = pos in stop_pos\n",
        "        v = vocab.get(key, { \"count\": 0, \"pos\": pos , \"stop\": is_stop})\n",
        "        v[\"count\"] += 1\n",
        "        vocab[key] = v\n",
        "\n",
        "vocab_list = []\n",
        "for k in vocab:\n",
        "    v = vocab[k]\n",
        "    if not v[\"stop\"]:\n",
        "        vocab_list.append((v[\"count\"], k, v[\"pos\"], v[\"stop\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lCsJpQnzhhIt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_list = sorted(vocab_list, reverse=True)\n",
        "vocab_list[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GnVZtE96hjy0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stop_word = [w[1] for w in vocab_list[:4]]\n",
        "stop_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tOwrS1_ZhmXC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "stop_word_regex = [ re.compile(\"^[!?]+$\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ma_zbpNLhpdU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_sentence_vector(sentence):\n",
        "    tokens = tokenize(sentence)\n",
        "    vecs = []\n",
        "    for token in tokens:\n",
        "        if is_stop(token):\n",
        "            continue\n",
        "        surface = token.surface\n",
        "        v = fasttext_model.query(surface)\n",
        "#         v = v / np.linalg.norm(v, axis=0, ord=2)\n",
        "        vecs.append(v)\n",
        "\n",
        "    sent_vec = None\n",
        "    for vec in vecs:\n",
        "        if sent_vec is None:\n",
        "            sent_vec = vec\n",
        "        else:\n",
        "            sent_vec = sent_vec + vec\n",
        "    return sent_vec\n",
        "\n",
        "def is_stop(token):\n",
        "    return token.pos in stop_pos or token.base in stop_word or any([r for r in stop_word_regex if r.match(token.base) is not None])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pCuGmYnRhsTb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_sentence_vector(\"与えられた文から文の分散表現を計算します。\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jxi0CKEwhudM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "for item in tqdm(items):\n",
        "    desc = item[\"desc\"]\n",
        "    desc_vec = get_sentence_vector(desc)\n",
        "    item[\"vec\"] = desc_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DERnyNfUhzuw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML, clear_output\n",
        "from html import escape\n",
        "\n",
        "def search_irasuto(sentence, top_n=3):\n",
        "    sentence_vector = get_sentence_vector(sentence)\n",
        "    sims = []\n",
        "    if sentence_vector is None:\n",
        "        print(\"検索できない文章です。もう少し文章を長くしてみてください。\")\n",
        "    else:\n",
        "        for item in items:\n",
        "            v = item[\"vec\"]\n",
        "            if v is None:\n",
        "                sims.append(-1.0)\n",
        "            else:\n",
        "                sim = cos_sim(sentence_vector, v)\n",
        "                sims.append(sim)\n",
        "    \n",
        "    count = 0\n",
        "    for index in np.argsort(sims)[::-1]:\n",
        "        if count >= top_n:\n",
        "            break\n",
        "        item = items[index]\n",
        "        desc = escape(item[\"desc\"])\n",
        "        imgs = item[\"imgs\"]\n",
        "        if len(imgs) == 0:\n",
        "            continue\n",
        "        img = imgs[0]\n",
        "        page = item[\"page\"]\n",
        "        sim = sims[index]\n",
        "        display(HTML(\"<div><a href='\" + page + \"' target='_blank' rel='noopener noreferrer'><img src='\" + img + \"' width='100'>\" + str(sim) + \": \" + desc + \"</a><div>\"))\n",
        "        count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yKIhqhnBh3U6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "search_irasuto(sentence=\"暴走したAI\", top_n=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v_YeSrnah5k6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "search_irasuto(sentence=\"いらすとやさんに惜しみない拍手を\", top_n=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Rovv_gDh8oT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "search_irasuto(sentence=\"つづく\", top_n=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CI-7oNwlh-zK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}